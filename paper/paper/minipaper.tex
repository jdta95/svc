% \documentclass[12pt]{article}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\input{preamble}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% DON'T change margins - should be 1 inch all around.
\addtolength{\oddsidemargin}{-.5in}%
\addtolength{\evensidemargin}{-1in}%
\addtolength{\textwidth}{1in}%
\addtolength{\textheight}{1.7in}%
\addtolength{\topmargin}{-1in}%

\begin{document}

\def\spacingset#1{\renewcommand{\baselinestretch}%
{#1}\small\normalsize} \spacingset{1}

\date{}

\newcommand{\footremember}[2]{%
    \footnote{#2}
    \newcounter{#1}
    \setcounter{#1}{\value{footnote}}%
}
\newcommand{\footrecall}[1]{%
    \footnotemark[\value{#1}]%
} 

\newcommand{\bbE}{\mathbb{E}}
\newcommand{\bbR}{\mathbb{R}}
\newcommand{\bX}{\boldsymbol{X}}
\newcommand{\bs}{\boldsymbol{s}}
\newcommand{\bw}{\boldsymbol{w}}
\newcommand{\bc}{\boldsymbol{c}}
\newcommand{\btheta}{\boldsymbol{\theta}}
\newcommand{\wtilde}{\tilde{w}}
\newcommand{\Ytilde}{\tilde{Y}}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newcommand{\mytitle}{\pkg{svc}: Spatially Varying Coefficient Models}  

\title{\bf \mytitle}
\author{Justice Akuoko-Frimpong, Edward Shao, Jonathan Ta}

\maketitle


\spacingset{1.9} % DON'T change the spacing. JASA template: 1.9!
\section{Introduction}
\label{sec:intro}

Heterogeneity in spatial processes presents significant challenges for traditional regression modeling approaches. Consider air pollution monitoring across an urban-rural gradient: the relationship between particulate matter (PM2.5) concentrations and predictor variables like traffic density or industrial emissions often varies substantially across space. Global regression models that assume constant coefficients fail to capture these localized relationships, potentially leading to incorrect scientific conclusions and suboptimal policy decisions.

Our work develops a computationally efficient Bayesian implementation of spatially varying coefficient (SVC) models, which address this limitation by allowing regression coefficients to change smoothly over space.

This flexible approach captures complex, location-dependent relationships while accounting for measurement error through an independent noise term. Our computational framework combines three innovations to enable efficient Bayesian inference: 
(1) a low-rank Gaussian process approximation for improved efficiency; 
(2) a robust adaptive Metropolis (RAM) to automatically achieve optimal acceptance rate for spatial decay random walk sampling; and
(3) optimized linear algebra operations using pre-computed distance matrices and Cholesky decompositions to accelerate covariance calculations. 
Together, these advances SVC models practical for large-scale environmental datasets.
\section{Methods}
\label{sec:methods}
\subsection{SVC Model}
\label{sec:model}
Let $\mathcal{D} \subset \mathbb{R}^2$ denote a spatial domain of interest, $s_i \in \mathcal{D}$ for each $i = 1, \dots, n$ denote a spatial location for which we have collected data, and $\bs = (s_1, \dots, s_n)^\top$ be the vector of all such locations. Then $Y(\bs)$ are univariate dependent variables and $\bX(\bs) = (X_1(\bs), \dots, X_p(\bs))^\top$ are $p \times 1$ vectors of covariates. A linear SVC regression model assumes $Y(\bs)$ are dependent on $\bX(\bs)$ as follows:
\begin{align*}
    Y(\bs) = \sum_{j=1}^p X_r(\bs)w_r(\bs) + \epsilon(\bs),
\end{align*}
where $w_r(\bs)$ are the regression coefficients corresponding to $X_r(\bs)$ and $\epsilon(\bs)$ are independently and identically distributed multivariate normal (MVN) measurement errors, i.e. $\epsilon(\bs) \sim \text{MVN}(0, \tau^2 I_n)$. Note that $X_1(\bs)$ can be defined as $\mathbf{1}_n$, a vector of length $n$ with every element equal to $1$. In this case, $w_1(\bs)$ would be equivalent to a spatially-correlated random intercept.

For each $w_r(\bs)$, we assign a Gaussian process (GP) prior with squared exponential covariance, i.e.
\begin{align*}
    w_r &\sim \text{GP}(0, C(\btheta_r)), \text{ where}\\
    C(\btheta_r) &= \left[C(s_i, s_{i'}; \btheta_r)\right]_{i, i' = 1}^n.
\end{align*}
We refer to $C(\cdot)$ as the covariance function, because the covariance of $w_r(s_i)$ and $w_r(s_{i'})$ at locations $s_i$ and $s_{i'}$ is $\sigma_r^2 C(\btheta_r)_{i, i'}$. In particular, we use the squared exponential covariance function where $\btheta_r = (\sigma_r^2, \phi_r)$,
\begin{align*}
    C(\btheta_r) &= \sigma_r^2 K(\phi_r), \text{ and}\\
    K(\phi_r) &= \left[ K(s_i, s_{i'}; \phi_r) \right]_{i, i' = 1}^n = \left[\exp\{\phi_r^{-1}\|s_i-s_{i'}\|^2\}\right]_{i, i' = 1}^n,
\end{align*}
due to its useful properties such as infinite smoothness and gradual decrease in covariance with distance. The parameter $\sigma_r^2$ is the spatial variance and $\phi_r$ is the spatial decay, which indicates how quickly correlation decreases with the squared distance.

We assign inverse-gamma conjugate priors for the variance parameters $\tau^2$ and each $\sigma_r^2$. In addition, each $phi_r$ is assigned a uniform prior. In summary, $\tau^2 \sim \text{Inv.Gamma}(\alpha_\tau, \beta_\tau)$, $\sigma_r^2 \sim \text{Inv.Gamma}(\alpha_r, \beta_r)$, and $\phi_r \sim \text{Uniform}(l_r, u_r)$.

\subsection{MCMC Algorithm}
\label{sec:mcmc}
The primary function in the \pkg{svc} package, \code{svclm}, samples from the joint posterior distribution of $w_r(\bs), \phi_r, \sigma_r^2,$ and $\tau^2$, for $r = 1, \dots, p$ using a Gibbs sampler. We will explain how each parameter is sampled at iteration $t+1$.

The parameter $\phi_r^{(t+1)}$ is updated via a random walk Metropolis algorithm. Because $\phi_r^{(t)} \in (l_r, u_r)$, each proposal is calculated as 
\begin{align*}
    \phi_r' &= f^{-1}(f(\phi_r^{(t)}) + U) = l_r + \frac{u_r - l_r}{1 + \exp\left\{\log\left(\frac{u_r - l_r}{\phi_r^{(t)} - l_r} - 1\right) + U\right\}},
\end{align*}
where $U$ is sampled from a normal distribution with mean $0$.

The initial standard deviation for $U$ is specified using the "phi\_proposal\_sd\_start" argument or is $1$ by default. Then the standard deviation is updated at each iteration via a Robust Adaptive Metropolis (RAM) algorithm as described by \cite{vihola}.

The sample the SVC's, let $\Ytilde(\bs) = Y(\bs) - \sum_{j\neq r} X_j(\bs)w_j^{(t)}(\bs)$. Then
\begin{align*}
    \frac{\Ytilde}{X_r}(\bs) | w_r^{(t)}(\bs), \tau^2 \sim \text{MVN} \left(w_r^{(t)}(\bs), \tau^{2(t)} \text{diag}\left( \frac{1}{X_r^2(\bs)} \right)\right) := \text{MVN} \left(\mu, \Sigma\right).
\end{align*}
Then assuming the prior $w_r(\bs) \sim \text{MVN}\left(0, C(\btheta_r^{(t)})\right) := \text{MVN}\left(0, \Sigma_0\right)$, we sample $w_r^{(t+1)}(\bs)$ from MVN$(\mu_1, \Sigma_1)$, where
\begin{align*}
    \Sigma_1 &= \left(\Sigma_0^{-1} + \Sigma^{-1}\right) \text{ and }
    \mu_1 = \Sigma_1 \Sigma^{-1} \frac{\Ytilde}{X_r}(s).
\end{align*}

We sample $\sigma_r^{2(t+1)}$ from Inv.Gamma$\left(\alpha_r + \frac{n}{2}, \beta_r + w_r^{(t)}(\bs)^{\top} K(\phi_r^{(t)})^{-1} w_r^{(t)}(\bs)\right)$.

We sample $\tau^{2(t+1)}$ from Inv.Gamma$\left(\alpha_t + \frac{n}{2}, \beta_t + \frac{1}{2} \left(Y(\bs) - \sum_{j=0}^p X_r(\bs)w_r^{(t)}(\bs) \right)\right)$.

\subsubsection{Low-Rank Gaussian Process}
\label{sec:low_rank}

We can perform the above algorithm using the complete data for all $n$ locations to estimate the full-rank Gaussian process model. However, notice that in each iteration, we must invert $C(\btheta_r^{(t)})$ for $r = 1, \dots, p$. In order to do so, we perform a Cholesky decomposition to obtain an upper triangular matrix $R$ and then invert $R$. These Cholesky decompositions on $p$ symmetric positive definite matrices of size $(n \times n)$ are the most flop-expensive operations in the algorithm resulting in an overall cost of $O(pn^3)$ per iteration. We can dramatically improve the efficiency of this algorithm with a low-rank Guassian process as described by \cite{banerjee}.

Consider a set of knots $\bs^* = (s_1^*, \dots, s_m^*)^\top$ which are a subset of locations $\bs$. With the low-rank Guassian process, we sample $\tau^2$, $\phi_r$, $\sigma_r^2$, and $\bw_r^* = \left[w(\bs_i^*)\right]_{i=1}^m$ which follows a multivariate Gaussian distribution with covariance matrix $C^*(\btheta_r) = \sigma_r^2 K^*(\phi_r) = \left[ \sigma_r^2 \exp\{ \phi_r^{-1} \| s_{i}^* - s_{i}^* \|^2 \} \right]_{i, i' = 1}^m$, for each $r = 1, \dots, p$.

Then for the original set of locations $\bs$, we predict the spatial interpolants 
\begin{align*}
    \wtilde_r(\bs) &= \bbE[w_r(\bs)|\bw_r^*] = \bc (\bs; \btheta_r) C^{*-1}(\btheta_r)\bw_r^*,
\end{align*}
where $\bc (\bs; \btheta_r)$ is an $n \times m$ matrix with $i, j$ element $c_{i, j} = \sigma_r^2 K(s_i, s_j^*; \phi_r) = \sigma_r^2 \exp\{\phi_r^{-1}\|s_i-s_j^*\|^2\}$.

Therefore, using the low-rank Gaussian process, we can replace $w_r(\bs)$ in the original model with $\wtilde_r(\bs)$ for each $r = 1, \dots, p$, but with an overall cost per iteration of $O(pm^3)$, where $m < n$.

\section{Using \pkg{svc}}
\label{sec:using}

To fit a linear SVC regression model using \pkg{svc}, we use the \code{svclm} function. In most cases, we recommend providing the following arguments to \code{svclm}: \code{Y}, \code{X}, \code{coords}, \code{Y\_knots}, \code{X\_knots}, \code{knots}, \code{phi\_lower}, \code{phi\_upper}, and \code{mcmc}. \code{Y} is a vector of length $n$ containing the response variable, \code{X} is the design matrix of size $n \times p$, and \code{coords} is a matrix of size $n \times 2$ containing the spatial coordinates of each location. The arguments \code{Y\_knots}, \code{X\_knots}, and \code{knots} provide the data for the knots that will be used in the low-rank model. \code{Y\_knots} is a vector of length $m$ containing the response variable at the knots, \code{X\_knots} is a matrix of size $m \times p$ containing the covariates at the knots, and \code{knots} is a matrix of size $m \times 2$ containing the spatial coordinates of each knot. The arguments \code{phi\_lower} and \code{phi\_upper} are each a vector of length $p$ containing the lower and upper bounds for the uniform distribution priors assigned to spatial decay parameters $\phi_r$, respectively. The argument \code{mcmc} is an integer specifying the number of MCMC iterations to run.

The minimum required arguments to run \code{svclm} are \code{Y}, \code{X}, \code{coords}, \code{phi\_lower}, and \code{phi\_upper}. In this case, the function will use the same data for the knots as for the full model essentially fitting the full Gaussian process model. The default number of MCMC iterations is $1000$.

We will not go into detail here since the arguments above should be sufficient for most use cases, but the \code{svclm} function does allow other arguments for additional settings. Users can specify starting values for $\tau^2$, $\sigma_r^2$, $\phi_r$, and $\bw_r^*$ where $r = 1, \dots, p$. They can also set the hyperparameters for the inverse gamma priors on $\tau^2$ and $\sigma_r^2$. Lastly, users can set the starting proposal standard deviations for each $\phi_r$ and the target acceptance rate for the RAM.

By default, the starting values for $\tau^2$, $\sigma_r^2$, $\phi_r$, and $\bw_r^*$ are set to $1$, $1$, the midpoint between the corresponding upper and lower bounds, and $0$ for all locations, respectively. The default priors for $\tau^2$ and each $\sigma_r^2$ are all Inv.Gamma$(0.001, 0.001)$ to achieve uninformative priors. The starting proposal standard deviations for each $\phi_r$ are set to $1$ by default, and the target acceptance rate for the RAM algorithm is set to $0.234$ which is the asymptotically optimal acceptance rate under most conditions \citep{gelman}.

In all cases, \code{svclm} returns a list containing the following matrices: \code{w\_samples}, an $(\code{mcmc} \times n \times p)$ array of the posterior samples for the SVC's; \code{phi\_samples}, an $(\code{mcmc} \times p)$ matrix of the posterior samples for the spatial decay parameters; \code{phi\_acceptance}, an $(\code{mcmc} \times p)$ matrix which is $1$ if the proposal for $\phi_r$ was accepted and $0$ otherwise; \code{sigmasq\_samples}, an $(\code{mcmc} \times p)$ matrix of the posterior samples for the spatial variances; and \code{tausq\_samples}, a $(\code{mcmc} \times 1)$ matrix of the posterior samples for the nugget parameter.

Although knot data can be chosen manually, the \pkg{svc} package also contains a function \code{simpleknots} to automatically select knots for the low-rank model. The function takes arguments \code{Y}, \code{X}, \code{coords}, and \code{k}, where \code{k} is an integer and \code{Y}, \code{X}, and \code{coords} match what would be provided to the \code{svclm} function. The function will return a list containing the objects \code{Y\_knots}, \code{X\_knots}, and \code{knots} which can then be passed directly to the \code{svclm} function. The knots are selected by sorting each dimension of coordinates and then selecting every $k$-th coordinate in each dimension.

\section{Simulation}
\label{sec:simulation}
% \begin{table}[ht!]
% \centering
% \caption{Covariate and response generation.}
% \label{tab:data-gen}
% \begin{tabular}{|c|l|}
% \hline
% \textbf{Variable} & \textbf{Distribution / Formula} \\
% \hline
% $ X_1 $ & $ \mathcal{N}(0, 1) $ \\
% $ X_2 $ & $ \mathcal{N}(5, 1) $ \\
% $ \epsilon $ & $ \mathcal{N}(0, \sigma^2_\epsilon) $, with $ \sigma^2_\epsilon = 0.1 $ \\
% $ Y $ & $ \beta_1 X_1 + \beta_2 X_2 + w + \epsilon $ \\
% \hline
% \end{tabular}
% \end{table}

% \subsection{Global Settings and Simulation Replication}
% 
% To assess the performance of our estimation procedures and reduce sampling variability, the entire data generation and model fitting pipeline is replicated 1000 times. Table~\ref{tab:settings} summarizes the global settings used throughout the simulations.

% \begin{table}[ht!]
% \centering
% \caption{Global simulation settings.}
% \label{tab:settings}
% \begin{tabular}{|c|l|}
% \hline
% \textbf{Setting} & \textbf{Value / Description} \\
% \hline
% Spatial grid size & $ 21 \times 21 = 441 $ locations \\
% Number of replications & 1000 \\
% Error variance $ \sigma^2_\epsilon $ & 0.1 \\
% Covariance function & Exponential kernel \\
% \hline
% \end{tabular}
% \end{table}

We compared the performance of our proposed method with \pkg{spBayes} using bias, RMSE, and computational time (in seconds), averaged over 1000 simulation replications. The true values for $ \beta_1 $, $ \beta_2 $, and $ w $ were all set to 1.

\begin{table}[ht!]
\centering
\caption{Comparison of methods based on bias, RMSE, and computation time (seconds). Placeholder values shown.}
\label{tab:method-compact}
\begin{tabular}{|l|ccc|ccc|ccc|}
\hline
\textbf{Method} 
& \multicolumn{3}{c|}{ $ \beta_1 $ } 
& \multicolumn{3}{c|}{ $ \beta_2 $ } 
& \multicolumn{3}{c|}{ $ w $ } \\
\cline{2-10}
& Bias & RMSE & Time 
& Bias & RMSE & Time 
& Bias & RMSE & Time \\
\hline
\pkg{svc} (low rank)
& -4.36 & 9.72 & 60.5
& -3.34 & 3.68 & 60.5 
& 1.15 & 2.11 & 60.5 \\
\pkg{spBayes} 
& -0.01 & 0.13 & 408 
& -0.03 & 0.07 & 408 
& 0.05 & 0.11 & 408 \\
\hline
\end{tabular}
\end{table}

\begin{figure}[H]
 \centering
 \includegraphics[width=\textwidth]{../../figures/SVCLM_sim.png}
 \caption{Posterior Mappings for Coefficients - SVCLM low rank}
 \label{fig:SVCLMA}
 \end{figure}


\begin{figure}[H]
 \centering
 \includegraphics[width=\textwidth]{../../figures/spBayes_sim.png}
 \caption{Posterior Mappings for Coefficients - spBayes}
 \label{fig:spBayesA}
 \end{figure}

\section{Data Analysis}
\label{sec:data analysis}
The real world data used in this section is a gridded satellite data with latitude, longitude, temperature, Normalized Difference Vegetation Index (NDVI); which measures greenness, and emissivity which represents a surface's efficiency in emitting thermal radiation \citep{hulley_new_2008, hulley_aster_2008, hulley_north_2009, hulley_validation_2009, hulley_generating_2011, hulley_quantifying_2012, nasa_jpl_aster_2014, hulley_span_2015}.
The data had 111,556 observations and 6 varibales namely, latitude, longitude, emissivity, NDVI and land surface tempareture (LST). Variables in the dataset were means computed from all clear-sky pixels of the Terra Advanced Spaceborne Thermal Emission and Reflection Radiometer (ASTER) scenes acquired from 2000 through 2008.
We used LST as a univariate outcome and used emissivity and NDVI as covariates.
Figure \ref{fig:spatialpatterns} below reveals the spatial  distributions of the variables in the dataset.

 \begin{figure}[H]
 \centering
 \includegraphics[width=\textwidth]{../../figures/spatial_horizontal_stack.png}
 \caption{
   Spatial distributions of emissivity, NDVI, and  land surface temperature in the study area. 
 }
 \label{fig:spatialpatterns}
 \end{figure}
 
  Emissivity ranged from 0.88 to 0.96, NDVI ranged from 0.2 to 0.6  and LST, from 290 to 320.  
 Cooler regions often align with greener (higher NDVI) areas — vegetation can reduce surface temperature through evapotranspiration.
\subsection{Model}
We modeled (LST) using an SVC framework:
\begin{align*}
\text{Temp}(\bs) &= w_1(\bs) + w_2(\bs)\cdot\text{NDVI} + w_3(\bs)\cdot\text{Emissivity} + \epsilon(\bs),
\end{align*}
with priors as specified in \ref{sec:model}.

We specified weakly informative priors: $\tau^2 \sim \text{Inv-Gamma}(0.001, 0.001)$, \newline $\sigma_r^2 \sim \text{Inv-Gamma}(0.001, 0.001)$, and $\phi_r \sim \text{Uniform}(0.001, 500)$, for each $r = 1, \dots 3$.

The computational implementation featured low-rank approximation. We selected 1 knot per 100 grid cells ($k=10$) using the  $\texttt{simpleknots()}$ function. Removed knots with missing data.
\subsection{Results}
\textbf{Convergence Diagnostics}\newline
We made trace plots after burn-in to check for convergence. 

\begin{figure}[H]
 \centering
 \includegraphics[width=\textwidth]{../../figures/traceplots.png}
 \caption{Trace plots for the parameters in the model}
 \label{fig:traceplots}
 \end{figure}
Some variables display stable and well-mixed behavior, suggesting convergence, while others show trends or irregular jumps which was expected in our setting.

\textbf{Interpretation of Coefficient Surfaces} \newline
Below is a plot of the posterior means of the coefficients at each location. The means were computed after burn-in.

\begin{figure}[H]
 \centering
 \includegraphics[width=\textwidth]{../../figures/model_means.png}
 \caption{Spatially varying coefficient surfaces for (A) NDVI and (B) Emissivity effects on land surface temperature}
 \label{fig:posterior means}
 \end{figure}
 The posterior mean NDVI coefficients show strong negative effects (cooling) across the entire study region, with values ranging from -0.7310 to -0.7300. 
 Each unit increase in NDVI corresponds to about $0.73^\circ C$ decrease in land surface temperature across space.
 The emissivity coefficients ranged from 325 to 340. These values revealed strong positive associations  which implies that across space, a unit increase in emissivity increases temperature.
 
 We generated predicted temperature values across the entire spatial domain using the posterior mean estimates of the SVC's. 
 These predictions were computed for all locations with complete predictor data, regardless of whether the actual temperature was observed. 
 The predicted values were obtained by multiplying the mean coefficient estimates with the corresponding covariate values at each location. 
 We then visualized both the observed and predicted temperature surfaces side by side to assess model performance and spatial prediction accuracy.
 
 
 \begin{figure}[H]
 \centering
 \includegraphics[width=\textwidth]{../../figures/predictions.png}
 \caption{Side by side plot of temperature and their predicted values across space. Gray indicates missing values.}
 \label{fig:predicted temperature}
 \end{figure}
 
 Note that the gray spaces in the plot are the locations with missing data. We can predict LST at locations with missing LST but cannot predict at locations with missing covariates; NDVI and emissivity.The figure comparison reveals the model’s ability to capture spatial patterns in LST, even in regions where observations were missing but predictor data were available.
 The range of values between the actual and predicted were close.
 
\section{Conclusion}
\label{sec:Conclusion}
The \pkg{svc} package provides a flexible and efficient framework for fitting SVC models that capture heterogeneous spatial processes. By leveraging low-rank Gaussian process approximations, RAM adaptation, and various sampling optimizations, we have made SVC models more computationally feasible for large-scale spatial datasets.

Compared to \pkg{spBayes}, our method performs................................

One limitation of our method is that it requires complete data at knot locations, whereas \pkg{spBayes} does not require any data at selected knot locations.

Further improvements to the package could include allowing for different covariance functions and implementing parallelization for sampling $\phi_r$ and $\sigma_r^2$ for $r = 1, \dots, p$ since the sampling can be done independently for each $r$.

\newpage

\bibliographystyle{agsm}

\bibliography{bibliography}
\end{document} 
