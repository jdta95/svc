phi_beta_proposal_sd = rep(0.1, p),
phi_w_proposal_sd = 0.1,
a_beta = rep(3, p),  # More informative priors
b_beta = rep(0.1, p),
a_w = 3,
b_w = 0.1,
a_t = 3,             # More informative prior for τ²
b_t = 0.1,
lower_beta = rep(0.1, p),
upper_beta = rep(10, p),
lower_w = 0.1,
upper_w = 10,
mcmc = 5000
)
# Analysis of results
burnin <- 3000
samples_keep <- burnin:5000
# Analysis of results
burnin <- 3000
samples_keep <- burnin:5000
# Plot tau^2 convergence
plot(output$tausq_samples, type = "l", main = "tau^2 samples")
abline(h = true_tausq, col = "red", lwd = 2)
cat("True tau^2:", true_tausq, "\nEstimated:", mean(output$tausq_samples[samples_keep]),
"\n95% CI:", quantile(output$tausq_samples[samples_keep], c(0.025, 0.975)), "\n")
# Plot sigma^2_w convergence
plot(output$sigmasq_w_samples, type = "l", main = "sigma^2_w samples")
abline(h = true_sigmasq_w, col = "red", lwd = 2)
cat("True sigma^2_w:", true_sigmasq_w, "\nEstimated:", mean(output$sigmasq_w_samples[samples_keep]),
"\n95% CI:", quantile(output$sigmasq_w_samples[samples_keep], c(0.025, 0.975)), "\n")
# Plot sigma^2_beta convergence
for (j in 1:p) {
plot(output$sigmasq_beta_samples[,j], type = "l",
main = paste("sigma^2_beta", j, "samples"))
abline(h = true_sigmasq_beta[j], col = "red", lwd = 2)
cat(paste0("\nTrue sigma^2_beta[", j, "]:"), true_sigmasq_beta[j],
"\nEstimated:", mean(output$sigmasq_beta_samples[samples_keep,j]),
"\n95% CI:", quantile(output$sigmasq_beta_samples[samples_keep,j], c(0.025, 0.975)), "\n")
}
# Function to calculate covariance matrix
calc_C_phi <- function(coords, phi) {
n <- nrow(coords)
C_phi <- matrix(0, nrow = n, ncol = n)
for (i in 1:n) {
for (j in 1:n) {
C_phi[i, j] <- exp(-0.5 * (sum((coords[i,] - coords[j,])^2) / phi))
}
}
return(C_phi)
}
set.seed(456)  # Different seed for generating a new dataset
# Simulate new data
set.seed(123)
lat <- seq(0, 10, by = 1)
lon <- seq(0, 10, by = 1)
coords <- as.matrix(expand.grid(lat, lon))
colnames(coords) <- c("lat", "lon")
n <- nrow(coords)
p <- 2
# Generating w (spatial random effects)
sigmasq_w <- 0.1  # Smaller variance
phi_w <- 2
C_w <- calc_C_phi(coords, phi_w)
w <- MASS::mvrnorm(1, rep(0, n), sigmasq_w * C_w)
# Generating beta's (spatially-varying coefficients)
sigmasq_1 <- 0.1  # Smaller variance
phi_1 <- 2
C_1 <- calc_C_phi(coords, phi_1)
beta_1 <- MASS::mvrnorm(1, rep(0, n), sigmasq_1 * C_1)
sigmasq_2 <- 0.1  # Smaller variance
phi_2 <- 2
C_2 <- calc_C_phi(coords, phi_2)
beta_2 <- MASS::mvrnorm(1, rep(0, n), sigmasq_2 * C_2)
# Generating X (covariates)
X_1 <- rnorm(n, 0, 1)  # Smaller variance
X_2 <- rnorm(n, 0, 1)  # Smaller variance
# Generating epsilon (measurement error)
tausq <- 0.01  # Smaller variance
epsilon <- rnorm(n, mean = 0, sd = sqrt(tausq))
# Generate knots
k <- 3
lat_knots <- unique(lat)
lat_knots <- lat_knots[seq(1, length(lat_knots), by = k)]
lon_knots <- unique(lon)
lon_knots <- lon_knots[seq(1, length(lon_knots), by = k)]
knots <- as.matrix(expand.grid(lat_knots, lon_knots))
# Prior parameters
a_t <- 1; b_t <- 1  # Prior for tau^2
a_r <- 1; b_r <- 1  # Prior for sigma_r^2
# Define beta as a vector of coefficients for X_1 and X_2
beta <- c(1, 1)  # Example coefficients for X_1 and X_2
# Subset beta_1 and beta_2 to match the dimensions of the knots
beta_1_knots <- beta_1[1:nrow(knots)]  # Use the first 16 values (assuming 16 knots)
beta_2_knots <- beta_2[1:nrow(knots)]  # Use the first 16 values
# Number of MCMC iterations
mcmc <- 1000
# Storage for posterior samples
tau2_samples <- numeric(mcmc)
sigma2_1_samples <- numeric(mcmc)
sigma2_2_samples <- numeric(mcmc)
# Initial values
tau2 <- 1  # Initial value for tau^2
sigma2_1 <- 1  # Initial value for sigma^2_1
sigma2_2 <- 1  # Initial value for sigma^2_2
# Store initial values in the first iteration
tau2_samples[1] <- tau2
sigma2_1_samples[1] <- sigma2_1
sigma2_2_samples[1] <- sigma2_2
# Run the Gibbs sampler with SCALED data
output <- svc::GP_Gibbs_test_tau_sigma(
Y = Y,
X = cbind(X_1, X_2),
s = coords,
knots = knots,
beta_knots_start = as.matrix(knots_df[, c("beta_1", "beta_2")]),
w_knots_start = knots_df$w,
phi_beta_start = true_phi[1:2],
phi_w_start = true_phi[3],
sigmasq_beta_start = rep(1, p),
sigmasq_w_start = 1,
tausq_start = 1,
phi_beta_proposal_sd = rep(0.1, p),
phi_w_proposal_sd = 0.1,
a_beta = rep(3, p),  # More informative priors
b_beta = rep(0.1, p),
a_w = 3,
b_w = 0.1,
a_t = 3,             # More informative prior for τ²
b_t = 0.1,
lower_beta = rep(0.1, p),
upper_beta = rep(10, p),
lower_w = 0.1,
upper_w = 10,
mcmc = 5000
)
# Analysis of results
burnin <- 3000
samples_keep <- burnin:5000
# Analysis of results
burnin <- 3000
samples_keep <- burnin:5000
# Plot tau^2 convergence
plot(output$tausq_samples, type = "l", main = "tau^2 samples")
abline(h = true_tausq, col = "red", lwd = 2)
cat("True tau^2:", true_tausq, "\nEstimated:", mean(output$tausq_samples[samples_keep]),
"\n95% CI:", quantile(output$tausq_samples[samples_keep], c(0.025, 0.975)), "\n")
# Plot sigma^2_w convergence
plot(output$sigmasq_w_samples, type = "l", main = "sigma^2_w samples")
abline(h = true_sigmasq_w, col = "red", lwd = 2)
cat("True sigma^2_w:", true_sigmasq_w, "\nEstimated:", mean(output$sigmasq_w_samples[samples_keep]),
"\n95% CI:", quantile(output$sigmasq_w_samples[samples_keep], c(0.025, 0.975)), "\n")
# Plot sigma^2_beta convergence
for (j in 1:p) {
plot(output$sigmasq_beta_samples[,j], type = "l",
main = paste("sigma^2_beta", j, "samples"))
abline(h = true_sigmasq_beta[j], col = "red", lwd = 2)
cat(paste0("\nTrue sigma^2_beta[", j, "]:"), true_sigmasq_beta[j],
"\nEstimated:", mean(output$sigmasq_beta_samples[samples_keep,j]),
"\n95% CI:", quantile(output$sigmasq_beta_samples[samples_keep,j], c(0.025, 0.975)), "\n")
}
library(data.table)
load("data/ASTER.RData")
setwd("C:/Lecture slides/Lecture slides/Lecture Slides/Winter 2025/Biostat 815/Quiz2/svc")
library(data.table)
load("data/ASTER.RData")
library(data.table)
library(here)
load(here("data", "ASTER.RData"))
library(viridis)    # for the viridis color scale
library(geoR)       # for calculating the empirical variogram
library(gridExtra)  # for arranging plots
# Spatial distribution of temperature
library(ggplot2)
ggplot(dt, aes(x=lon, y=lat, color=temp)) +
geom_point() +
scale_color_gradient(low="blue", high="red") +
ggtitle("Spatial Temperature Distribution")
# Spatial distribution of ndvi
ggplot(dt, aes(x=lon, y=lat, color=ndvi)) +
geom_point() +
scale_color_gradient(low="blue", high="red") +
ggtitle("Spatial ndvi Distribution")
# Spatial distribution of emis
ggplot(dt, aes(x=lon, y=lat, color=emis)) +
geom_point() +
scale_color_gradient(low="blue", high="red") +
ggtitle("Spatial emissivity Distribution")
# Load packages
library(sp)
library(gstat)
coordinates(dt) <- ~lon + lat
# Remove rows with NA in temp
dt_complete <- dt[!is.na(dt$temp), ]
v <- variogram(temp ~ 1, data = dt_complete)
plot(v, main = "Temperature Variogram")
load(here("data", "ASTER.RData"))
library(svc)
complete_cases <- complete.cases(dt)
dt_complete <- dt[complete_cases, ]
# Create standardized inputs
Y <- dt_complete$temp
X <- scale(as.matrix(dt_complete[, c("ndvi", "emis")]))
s <- scale(as.matrix(dt_complete[, c("lon", "lat")]))
# Knot creation function with checks
create_knots <- function(coords, k = 50) {
if(!all(c("lat", "lon") %in% colnames(coords))) {
stop("coords must contain 'lat' and 'lon' columns")
}
lat_knots <- unique(na.omit(coords[,"lat"]))
lon_knots <- unique(na.omit(coords[,"lon"]))
lat_knots <- lat_knots[seq(1, length(lat_knots), by = k)]
lon_knots <- lon_knots[seq(1, length(lon_knots), by = k)]
knots <- as.matrix(expand.grid(lat_knots, lon_knots))
colnames(knots) <- c("lat", "lon")
return(knots)
}
# Create and validate knots
coords <- as.data.frame(dt_complete[, c("lat", "lon")])
knots <- create_knots(coords, k = 50)
knots_df <- merge(data.frame(knots), dt_complete, by = c("lat", "lon"), all.x = TRUE)
complete_knots <- complete.cases(knots_df[, c("temp", "ndvi", "emis")])
# Filter all components to only keep complete cases
knots_df <- knots_df[complete_knots, ]
Y_knots <- knots_df$temp
X_knots <- as.matrix(knots_df[, c("ndvi", "emis")])
knots_matrix <- as.matrix(knots_df[, c("lon", "lat")])
# Now scale the complete data
X_knots <- scale(X_knots)
knots_matrix <- scale(knots_matrix)
# Initial values with small phi's for stability
init_values <- list(
beta_knots_start = matrix(rnorm(nrow(knots_matrix)*ncol(X), sd = 0.1),
nrow = nrow(knots_matrix), ncol = ncol(X)),
w_knots_start = rnorm(nrow(knots_matrix), sd = 0.1),
phi_beta_start = rep(0.01, ncol(X)),  # Very small initial phi values
phi_w_start = 0.01,
sigmasq_beta_start = rep(0.1, ncol(X)),
sigmasq_w_start = 0.1,
tausq_start = 0.001
)
# bounds and small proposal sizes for phi's
tuning_params <- list(
phi_beta_proposal_sd = rep(0.005, ncol(X)),  # Small steps
phi_w_proposal_sd = 0.005,
lower_beta = rep(0.001, ncol(X)),  # Tight bounds
upper_beta = rep(0.5, ncol(X)),
lower_w = 0.001,
upper_w = 0.5
)
# Weakly informative priors
priors <- list(
a_beta = rep(2, ncol(X)),  # Slightly informative
b_beta = rep(1, ncol(X)),
a_w = 2,
b_w = 1,
a_t = 2,
b_t = 1
)
# Run model with error handling
results <- GP_Gibbs(
Y = Y,
X = X,
s = s,
knots = knots_matrix,
Y_knots = Y_knots,
X_knots = X_knots,
beta_knots_start = init_values$beta_knots_start,
w_knots_start = init_values$w_knots_start,
phi_beta_start = init_values$phi_beta_start,
phi_w_start = init_values$phi_w_start,
sigmasq_beta_start = init_values$sigmasq_beta_start,
sigmasq_w_start = init_values$sigmasq_w_start,
tausq_start = init_values$tausq_start,
phi_beta_proposal_sd = tuning_params$phi_beta_proposal_sd,
phi_w_proposal_sd = tuning_params$phi_w_proposal_sd,
a_beta = priors$a_beta,
b_beta = priors$b_beta,
a_w = priors$a_w,
b_w = priors$b_w,
a_t = priors$a_t,
b_t = priors$b_t,
lower_beta = tuning_params$lower_beta,
upper_beta = tuning_params$upper_beta,
lower_w = tuning_params$lower_w,
upper_w = tuning_params$upper_w,
mcmc = 1000
)
library(ggplot2)
library(tidyr)
# Convert samples to data frame
trace_data <- data.frame(
iteration = 1:length(results$phi_w_samples),
phi_beta_ndvi = results$phi_beta_samples[,1],
phi_beta_emis = results$phi_beta_samples[,2],
phi_w = results$phi_w_samples,
sigmasq_beta_ndvi = results$sigmasq_beta_samples[,1],
sigmasq_beta_emis = results$sigmasq_beta_samples[,2],
sigmasq_w = results$sigmasq_w_samples,
tausq = results$tausq_samples
)
# Create faceted trace plots
trace_long <- trace_data %>%
pivot_longer(-iteration, names_to = "parameter", values_to = "value")
ggplot(trace_long, aes(x = iteration, y = value)) +
geom_line(alpha = 0.7) +
facet_wrap(~ parameter, scales = "free_y", ncol = 2) +
labs(title = "MCMC Trace Plots", x = "Iteration", y = "Parameter Value") +
theme_minimal()
# Trace plots for NDVI coefficient at selected locations
plot(results$beta_samples[5, 1, ], type = 'l',
main = "Beta NDVI - Location 1", ylab = "Coefficient Value")
plot(results$beta_samples[10, 1, ], type = 'l',
main = "Beta NDVI - Location 10", ylab = "Coefficient Value")
# Trace plots for Emissivity coefficient at selected locations
plot(results$beta_samples[1, 2, ], type = 'l',
main = "Beta Emissivity - Location 1", ylab = "Coefficient Value")
plot(results$beta_samples[10, 2, ], type = 'l',
main = "Beta Emissivity - Location 10", ylab = "Coefficient Value")
library(ggplot2)
library(tidyr)
# Convert samples to data frame
trace_data <- data.frame(
iteration = 1:length(results$phi_w_samples),
phi_beta_ndvi = results$phi_beta_samples[,1],
phi_beta_emis = results$phi_beta_samples[,2],
phi_w = results$phi_w_samples,
sigmasq_beta_ndvi = results$sigmasq_beta_samples[,1],
sigmasq_beta_emis = results$sigmasq_beta_samples[,2],
sigmasq_w = results$sigmasq_w_samples,
tausq = results$tausq_samples
)
# Create faceted trace plots
trace_long <- trace_data %>%
pivot_longer(-iteration, names_to = "parameter", values_to = "value")
ggplot(trace_long, aes(x = iteration, y = value)) +
geom_line(alpha = 0.7) +
facet_wrap(~ parameter, scales = "free_y", ncol = 2) +
labs(title = "MCMC Trace Plots", x = "Iteration", y = "Parameter Value") +
theme_minimal()
# Spatial distribution of temperature
library(ggplot2)
# map emis, ndvi, and elev
emis.map = ggplot(dt, aes(lon, lat)) +
geom_tile(aes(fill = emis)) +
xlab("longitude") +
ylab("latitude") +
guides(fill = guide_legend(title = "emissivity")) +
coord_fixed()
emis.map
ggplot(dt, aes(lon, lat)) +
geom_tile(aes(fill = emis)) +
xlab("longitude") +
ylab("latitude") +
guides(fill = guide_legend(title = "emissivity")) +
ggtitle("Spatial Temperature Distribution") +
coord_fixed()
ggplot(dt, aes(lon, lat)) +
geom_tile(aes(fill = emis)) +
xlab("longitude") +
ylab("latitude") +
guides(fill = guide_legend(title = "emissivity")) +
ggtitle("Spatial emissivity Distribution") +
coord_fixed()
ggplot(dt, aes(lon, lat)) +
geom_tile(aes(fill = ndvi)) +
xlab("longitude") +
ylab("latitude") +
guides(fill = guide_legend(title = "NDVI")) +
ggtitle("Spatial ndvi Distribution") +
coord_fixed()
ggplot(dt, aes(lon, lat)) +
geom_tile(aes(fill = temp)) +
xlab("longitude") +
ylab("latitude") +
guides(fill = guide_legend(title = "elevation")) +
ggtitle("Spatial temperature Distribution") +
coord_fixed()
library(viridis)    # for the viridis color scale
library(geoR)       # for calculating the empirical variogram
library(gridExtra)  # for arranging plots
# Spatial distribution of temperature
library(ggplot2)
ggplot(dt, aes(lon, lat)) +
geom_tile(aes(fill = emis)) +
xlab("longitude") +
ylab("latitude") +
guides(fill = guide_legend(title = "emissivity")) +
ggtitle("Spatial emissivity Distribution") +
coord_fixed()
ggplot(dt, aes(lon, lat)) +
geom_tile(aes(fill = ndvi)) +
xlab("longitude") +
ylab("latitude") +
guides(fill = guide_legend(title = "NDVI")) +
ggtitle("Spatial ndvi Distribution") +
coord_fixed()
ggplot(dt, aes(lon, lat)) +
geom_tile(aes(fill = temp)) +
xlab("longitude") +
ylab("latitude") +
guides(fill = guide_legend(title = "temperature")) +
ggtitle("Spatial temperature Distribution") +
coord_fixed()
# subset data further for more efficient semivariogram analysis
lat.sub = dt[, unique(lat)]
lat.sub = lat.sub[seq(1, length(lat.sub), by = 2)]
lon.sub = dt[, unique(lon)]
lon.sub = lon.sub[seq(1, length(lon.sub), by = 2)]
dt.sub = dt[lat %in% lat.sub & lon %in% lon.sub]
# semivariogram of emissivity
sv = variog(
coords = cbind(dt.sub[!is.na(emis), lat], dt.sub[!is.na(emis), lon]),
data = dt.sub[!is.na(emis), emis]
)
sv.dt = data.table(
dists = sv$u,
variogram = sv$v,
npairs = sv$n,
sd = sv$sd
)
sv.plot = ggplot(sv.dt, aes(x = dists, y = variogram)) +
geom_point() +
labs(title = "emissivity semivariogram")
png(
filename = paste0(path_tabfig, "sv.EMIS.png"),
width = 1080,
height = 1080
)
ggplot(sv.dt, aes(x = dists, y = variogram)) +
geom_point() +
labs(title = "emissivity semivariogram")
# identifying min and max distances
summary(sv.dt)
# semivariogram of NDVI
sv = variog(
coords = cbind(dt.sub[, lat], dt.sub[, lon]),
data = dt.sub[, ndvi]
)
library(data.table)
library(here)
load(here("data", "ASTER.RData"))
# subset data further for more efficient semivariogram analysis
lat.sub = dt[, unique(lat)]
lat.sub = lat.sub[seq(1, length(lat.sub), by = 2)]
lon.sub = dt[, unique(lon)]
lon.sub = lon.sub[seq(1, length(lon.sub), by = 2)]
dt.sub = dt[lat %in% lat.sub & lon %in% lon.sub]
# semivariogram of NDVI
sv = variog(
coords = cbind(dt.sub[, lat], dt.sub[, lon]),
data = dt.sub[, ndvi]
)
# semivariogram of temperature
sv = variog(
coords = cbind(dt.sub[, lat], dt.sub[, lon]),
data = dt.sub[, temp]
)
# subset data further for more efficient semivariogram analysis
lat.sub = dt[, unique(lat)]
lat.sub = lat.sub[seq(1, length(lat.sub), by = 2)]
lon.sub = dt[, unique(lon)]
lon.sub = lon.sub[seq(1, length(lon.sub), by = 2)]
dt.sub = dt[lat %in% lat.sub & lon %in% lon.sub]
dt.sub = dt.sub[complete.cases(dt.sub[, c("lat", "lon", "ndvi", "temp")]), ]
# semivariogram of emissivity
sv = variog(
coords = cbind(dt.sub[!is.na(emis), lat], dt.sub[!is.na(emis), lon]),
data = dt.sub[!is.na(emis), emis]
)
sv.dt = data.table(
dists = sv$u,
variogram = sv$v,
npairs = sv$n,
sd = sv$sd
)
ggplot(sv.dt, aes(x = dists, y = variogram)) +
geom_point() +
labs(title = "emissivity semivariogram")
# identifying min and max distances
summary(sv.dt)
# semivariogram of NDVI
sv = variog(
coords = cbind(dt.sub[, lat], dt.sub[, lon]),
data = dt.sub[, ndvi]
)
sv.dt = data.table(
dists = sv$u,
variogram = sv$v,
npairs = sv$n,
sd = sv$sd
)
ggplot(sv.dt, aes(x = dists, y = variogram)) +
geom_point() +
labs(title = "NDVI semivariogram")
# identifying min and max distances
summary(sv.dt)
# semivariogram of temperature
sv = variog(
coords = cbind(dt.sub[, lat], dt.sub[, lon]),
data = dt.sub[, temp]
)
sv.dt = data.table(
dists = sv$u,
variogram = sv$v,
npairs = sv$n,
sd = sv$sd
)
ggplot(sv.dt, aes(x = dists, y = variogram)) +
geom_point() +
labs(title = "temperature semivariogram")
# identifying min and max distances
summary(sv.dt)
